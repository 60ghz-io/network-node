From 956652b37c0ac46c37c03309bc1e4ebc457867db Mon Sep 17 00:00:00 2001
From: Frank Li <frankli1@fb.com>
Date: Sun, 13 Sep 2020 23:50:13 -0700
Subject: [PATCH] Support jumbo frame transmission for wil6210-pmd

---
 src/plugins/dpdk/device/device.c | 364 ++++++++++++++++++++++++++++++-
 src/plugins/dpdk/device/dpdk.h   |  21 ++
 src/plugins/dpdk/device/node.c   | 139 ++++++++++++
 src/vnet/ethernet/ethernet.h     |   2 +-
 src/vnet/ethernet/types.def      |   1 +
 5 files changed, 522 insertions(+), 5 deletions(-)

diff --git a/src/plugins/dpdk/device/device.c b/src/plugins/dpdk/device/device.c
index 5359f8803..e9ad7a5d3 100644
--- a/src/plugins/dpdk/device/device.c
+++ b/src/plugins/dpdk/device/device.c
@@ -21,11 +21,14 @@
 #include <dpdk/buffer.h>
 #include <dpdk/device/dpdk.h>
 #include <dpdk/device/dpdk_priv.h>
+#include <dpdk/dynfield/dynfield.h>
 #include <vppinfra/error.h>
 
 #define foreach_dpdk_tx_func_error			\
   _(BAD_RETVAL, "DPDK tx function returned an error")	\
-  _(PKT_DROP, "Tx packet drops (dpdk tx failure)")
+  _(PKT_DROP, "Tx packet drops (dpdk tx failure)")	\
+  _(JUMBO_FRAME_INCOMPLETE,				\
+    "Failed to send all packet segments of a jumbo frame")
 
 typedef enum
 {
@@ -278,6 +281,257 @@ dpdk_buffer_tx_offload (dpdk_device_t * xd, vlib_buffer_t * b,
     rte_net_intel_cksum_flags_prepare (mb, ol_flags);
 }
 
+/**
+ * Terragraph: Takes a jumbo frame and breaks up the mbuf chain to transmit
+ * each mbuf segment as an individual packet. Creates a Terragraph
+ * ethernet segmentation header for each packet, which provides information
+ * necessary for reassembly. This function also enqueues the jumbo frame
+ * packets for transmission.
+ */
+static_always_inline void
+tg_jumbo_frame_segmentation_tx (dpdk_device_t *xd, struct rte_mbuf *mb0)
+{
+  dpdk_main_t *dm = &dpdk_main;
+  tghqos_main_t *tm = &tghqos_main;
+  vlib_main_t *vm = vlib_get_main ();
+  ethernet_header_t *e0;
+  struct rte_mbuf *mb, *mb_next;
+  int i, segs, link_id, n_sent, n_left, do_free;
+  tg_seg_header_t tg_hdr;
+  vlib_buffer_t *b;
+
+  struct rte_mbuf *mbufs[TG_JUMBO_FRAME_SEG_ARRAY_LEN] = {0};
+  u16 bytes_to_shift[TG_JUMBO_FRAME_SEG_ARRAY_LEN] = {0};
+  u16 bytes_to_copy_to_next[TG_JUMBO_FRAME_SEG_ARRAY_LEN] = {0};
+
+  u16 tg_hdr_size = sizeof (tg_seg_header_t);
+  u16 headroom, tailroom, running_bytes;
+
+  /* Copy ethernet src/dst information from original packet. */
+  b = vlib_buffer_from_rte_mbuf (mb0);
+  e0 = (void *)(b->data + vnet_buffer (b)->l2_hdr_offset);
+  for (i = 0; i < 6; i++)
+    {
+      tg_hdr.e.dst_address[i] = e0->dst_address[i];
+      tg_hdr.e.src_address[i] = e0->src_address[i];
+    }
+
+  tg_hdr.e.type = clib_host_to_net_u16 (ETHERNET_TYPE_TG_JUMBO);
+  tg_hdr.protocol_version = TG_JUMBO_FRAME_PROTOCOL_VERSION;
+  tg_hdr.packet_id = xd->tg_jumbo_frame_tx_id++;
+
+  segs = mb0->nb_segs;
+  /* TODO: handle better */
+  if (segs > TG_JUMBO_FRAME_SEG_ARRAY_LEN)
+    {
+      dpdk_log_err ("Interface %U: too many segments (%d > %d) in wil6210-pmd "
+                    "jumbo frame transmission; dropping packet",
+                    format_dpdk_device_name, xd->port_id, segs,
+                    TG_JUMBO_FRAME_SEG_ARRAY_LEN);
+      rte_pktmbuf_free (mb0);
+      return;
+    }
+
+  /* Link id will be used for sorting jumbo frame segments for reassembly. */
+  link_id = wigig_mbuf_link_id_get (mb0);
+
+  /*
+   * Set the HQoS metadata for the original packet before segmentation headers
+   * are inserted since the offset of the DSCP field will change afterwards.
+   */
+  if (xd->flags & DPDK_DEVICE_FLAG_HQOS)
+    {
+      tghqos_set_metadata (&mb0, 1);
+    }
+
+  /*
+   * For each mbuf segment, calculate number of bytes by which it needs to
+   * shift its data and number of bytes it needs copied to the next segment in
+   * order to insert headers for every segment.
+   *
+   * No assumptions are made about the headroom or tailroom that is available
+   * in each segment; some drivers leave headroom while others do not.
+   */
+  running_bytes = 0;
+  mb_next = mb0;
+  for (i = 0; i < segs; i++)
+    {
+      mb = mb_next;
+
+      running_bytes += tg_hdr_size;
+      headroom = rte_pktmbuf_headroom (mb);
+      if (headroom >= running_bytes)
+        {
+          running_bytes = 0;
+        }
+      else
+        {
+          running_bytes -= headroom;
+        }
+      bytes_to_shift[i] = running_bytes;
+
+      tailroom = rte_pktmbuf_tailroom (mb);
+      if (tailroom >= running_bytes)
+        {
+          running_bytes = 0;
+        }
+      else
+        {
+          running_bytes -= tailroom;
+        }
+      bytes_to_copy_to_next[i] = running_bytes;
+
+      mbufs[i] = mb;
+      mb_next = mb->next;
+    }
+
+  /* We need to chain an extra mbuf if there are bytes that need to
+   * be copied from the last segment. */
+  if (bytes_to_copy_to_next[segs - 1] > 0)
+    {
+      segs++;
+      /* TODO: handle better */
+      if (segs > TG_JUMBO_FRAME_SEG_ARRAY_LEN)
+        {
+          dpdk_log_err (
+              "Interface %U: too many segments (%d > %d) in wil6210-pmd "
+              "jumbo frame transmission; dropping packet",
+              format_dpdk_device_name, xd->port_id, segs,
+              TG_JUMBO_FRAME_SEG_ARRAY_LEN);
+          rte_pktmbuf_free (mb0);
+          return;
+        }
+
+      /* unsure if this is bad to do here but we need to get an extra mbuf
+       * somehow (?) */
+      u16 socket_id = rte_lcore_to_socket_id (rte_lcore_id ());
+      u8 bpidx = vlib_buffer_pool_get_default_for_numa (vm, socket_id);
+      vlib_buffer_pool_t *bp = vlib_get_buffer_pool (vm, bpidx);
+      struct rte_mempool *mp = dpdk_mempool_by_buffer_pool_index[bpidx];
+
+      mbufs[segs - 1] = rte_pktmbuf_alloc (mp);
+      /* TODO: handle better */
+      if (mbufs[segs - 1] == NULL)
+        {
+          dpdk_log_err (
+              "Interface %U: failed to alloc new rte_mbuf for jumbo frame tx",
+              format_dpdk_device_name, xd->port_id);
+            return;
+        }
+      mbufs[segs - 1]->data_len = bytes_to_copy_to_next[segs - 2];
+    }
+
+  /* Iterate through mbufs backwards to shift/copy data and insert headers. */
+  for (i = segs - 1; i >= 0; i--)
+    {
+      u16 shift_bytes = bytes_to_shift[i];
+      u16 copy_bytes = 0;
+      struct rte_mbuf *mb_from;
+
+      mb = mbufs[i];
+      if (i > 0)
+        {
+          mb_from = mbufs[i - 1];
+          copy_bytes = bytes_to_copy_to_next[i - 1];
+        }
+
+      if (shift_bytes > 0)
+        {
+          memmove (mb->buf_addr + mb->data_off + shift_bytes,
+                   mb->buf_addr + mb->data_off,
+                   mb->data_len - bytes_to_copy_to_next[i]);
+        }
+
+      /* Calculate new data offset to make sure bytes get copied correctly. */
+      mb->data_off =
+          mb->data_off > tg_hdr_size ? mb->data_off - tg_hdr_size : 0;
+
+      if (copy_bytes > 0)
+        {
+          clib_memcpy_fast (mb->buf_addr + mb->data_off + tg_hdr_size,
+                            mb_from->buf_addr + mb_from->data_len - copy_bytes,
+                            copy_bytes);
+        }
+
+      /* Set remaining mbuf fields to cut chain and insert header. */
+      wigig_mbuf_link_id_set (mb, link_id);
+      mb->nb_segs = 1;
+      mb->data_len = clib_min (
+          mb->data_len + clib_max (shift_bytes, tg_hdr_size), mb->buf_len);
+      mb->pkt_len = mb->data_len;
+      mb->next = NULL;
+
+      tg_hdr.seg_index = i;
+      tg_hdr.last_seg = (i == segs - 1);
+      clib_memcpy_fast (mb->buf_addr + mb->data_off, &tg_hdr, tg_hdr_size);
+    }
+
+  if (xd->flags & DPDK_DEVICE_FLAG_HQOS)
+    {
+      /* Copy the HQoS metadata from the first packet to the rest of the
+       * segment packets. */
+      for (i = 1; i < segs; i++)
+        {
+          clib_memcpy_fast (&mbufs[i]->hash.sched, &mbufs[0]->hash.sched,
+                            sizeof (mbufs[0]->hash.sched));
+        }
+      if (tm->cpu_count == 0)
+        {
+          tghqos_port_lock (xd->port_id);
+          n_sent = tghqos_port_enqueue (xd->port_id, mbufs, segs);
+          tghqos_port_unlock (xd->port_id);
+          do_free = 0;
+        }
+      else
+        {
+          n_sent = tghqos_port_thread_enqueue (xd->port_id, mbufs, segs,
+                                               vm->thread_index);
+          do_free = 1;
+        }
+    }
+  else
+    {
+      int queue_id = vm->thread_index % xd->tx_q_used;
+      dpdk_tx_queue_t *txq = vec_elt_at_index (xd->tx_queues, queue_id);
+
+      clib_spinlock_lock_if_init (&txq->lock);
+      n_sent = rte_eth_tx_burst (xd->port_id, queue_id, mbufs, segs);
+      do_free = 1;
+      clib_spinlock_unlock_if_init (&txq->lock);
+    }
+
+  n_left = segs - n_sent;
+  if (n_left)
+    {
+      dpdk_main_t *dm = &dpdk_main;
+      vnet_main_t *vnm = dm->vnet_main;
+      vnet_interface_main_t *im = &vnm->interface_main;
+      vlib_simple_counter_main_t *cm;
+      u32 node_index;
+
+      node_index =
+          vec_elt_at_index (im->hw_interfaces, xd->hw_if_index)->tx_node_index;
+
+      vlib_error_count (vm, node_index,
+                        DPDK_TX_FUNC_ERROR_JUMBO_FRAME_INCOMPLETE, 1);
+
+      cm = vec_elt_at_index (vnm->interface_main.sw_if_counters,
+                             VNET_INTERFACE_COUNTER_TX_ERROR);
+
+      vlib_increment_simple_counter (cm, vm->thread_index, xd->sw_if_index,
+                                     n_left);
+
+      vlib_error_count (vm, node_index, DPDK_TX_FUNC_ERROR_PKT_DROP,
+                        n_left);
+
+      if (do_free)
+        {
+          while (n_left--)
+            rte_pktmbuf_free (mbufs[segs - n_left - 1]);
+        }
+    }
+}
+
 /*
  * Transmits the packets on the frame to the interface associated with the
  * node. It first copies packets on the frame to a per-thread arrays
@@ -297,9 +551,10 @@ VNET_DEVICE_CLASS_TX_FN (dpdk_device_class) (vlib_main_t * vm,
   u32 tx_pkts = 0, all_or_flags = 0;
   dpdk_per_thread_data_t *ptd = vec_elt_at_index (dm->per_thread_data,
 						  thread_index);
-  struct rte_mbuf **mb;
+  struct rte_mbuf **mb, **mb_replace;
   vlib_buffer_t *b[4];
   int do_free;
+  int n_removed = 0;
 
   ASSERT (n_packets <= VLIB_FRAME_SIZE);
 
@@ -309,12 +564,13 @@ VNET_DEVICE_CLASS_TX_FN (dpdk_device_class) (vlib_main_t * vm,
 				-(i32) sizeof (struct rte_mbuf));
 
   n_left = n_packets;
-  mb = ptd->mbufs;
+  mb_replace = mb = ptd->mbufs;
 
 #if (CLIB_N_PREFETCHES >= 8)
   while (n_left >= 8)
     {
       u32 or_flags;
+      int remove_0 = 0, remove_1 = 0, remove_2 = 0, remove_3 = 0;
 
       dpdk_prefetch_buffer (vm, mb[4]);
       dpdk_prefetch_buffer (vm, mb[5]);
@@ -373,6 +629,51 @@ VNET_DEVICE_CLASS_TX_FN (dpdk_device_class) (vlib_main_t * vm,
 	    dpdk_tx_trace_buffer (dm, node, xd, queue_id, b[3]);
 	}
 
+      /* Terragraph: Handle jumbo frames by segmenting and transmitting mbufs
+       * individually. Remove jumbo frames from the mbuf array after they have
+       * already been enqueued for transmission.
+       */
+      if (rte_pktmbuf_pkt_len (mb[0]) > TG_WIL6210_NO_JUMBO_SEG_MTU &&
+          xd->pmd == VNET_DPDK_PMD_WIL6210)
+        {
+          tg_jumbo_frame_segmentation_tx (xd, mb[0]);
+          remove_0 = 1;
+          n_removed++;
+        }
+      if (rte_pktmbuf_pkt_len (mb[1]) > TG_WIL6210_NO_JUMBO_SEG_MTU &&
+          xd->pmd == VNET_DPDK_PMD_WIL6210)
+        {
+          tg_jumbo_frame_segmentation_tx (xd, mb[1]);
+          remove_1 = 1;
+          n_removed++;
+        }
+      if (rte_pktmbuf_pkt_len (mb[2]) > TG_WIL6210_NO_JUMBO_SEG_MTU &&
+          xd->pmd == VNET_DPDK_PMD_WIL6210)
+        {
+          tg_jumbo_frame_segmentation_tx (xd, mb[2]);
+          remove_2 = 1;
+          n_removed++;
+        }
+      if (rte_pktmbuf_pkt_len (mb[3]) > TG_WIL6210_NO_JUMBO_SEG_MTU &&
+          xd->pmd == VNET_DPDK_PMD_WIL6210)
+        {
+          tg_jumbo_frame_segmentation_tx (xd, mb[3]);
+          remove_3 = 1;
+          n_removed++;
+        }
+
+      if (n_removed > 0) {
+        mb_replace[0] = mb[0];
+        mb_replace -= remove_0;
+        mb_replace[1] = mb[1];
+        mb_replace -= remove_1;
+        mb_replace[2] = mb[2];
+        mb_replace -= remove_2;
+        mb_replace[3] = mb[3];
+        mb_replace -= remove_3;
+      }
+      mb_replace += 4;
+
       mb += 4;
       n_left -= 4;
     }
@@ -381,6 +682,7 @@ VNET_DEVICE_CLASS_TX_FN (dpdk_device_class) (vlib_main_t * vm,
     {
       vlib_buffer_t *b2, *b3;
       u32 or_flags;
+      int remove_0 = 0, remove_1 = 0;
 
       CLIB_PREFETCH (mb[2], CLIB_CACHE_LINE_BYTES, STORE);
       CLIB_PREFETCH (mb[3], CLIB_CACHE_LINE_BYTES, STORE);
@@ -427,6 +729,33 @@ VNET_DEVICE_CLASS_TX_FN (dpdk_device_class) (vlib_main_t * vm,
 	    dpdk_tx_trace_buffer (dm, node, xd, queue_id, b[1]);
 	}
 
+      /* Terragraph: Handle jumbo frames by segmenting and transmitting mbufs
+       * individually. Remove jumbo frames from the mbuf array after they have
+       * already been enqueued for transmission.
+       */
+      if (rte_pktmbuf_pkt_len (mb[0]) > TG_WIL6210_NO_JUMBO_SEG_MTU &&
+          xd->pmd == VNET_DPDK_PMD_WIL6210)
+        {
+          tg_jumbo_frame_segmentation_tx (xd, mb[0]);
+          remove_0 = 1;
+          n_removed++;
+        }
+      if (rte_pktmbuf_pkt_len (mb[1]) > TG_WIL6210_NO_JUMBO_SEG_MTU &&
+          xd->pmd == VNET_DPDK_PMD_WIL6210)
+        {
+          tg_jumbo_frame_segmentation_tx (xd, mb[1]);
+          remove_1 = 1;
+          n_removed++;
+        }
+
+      if (n_removed > 0) {
+        mb_replace[0] = mb[0];
+        mb_replace -= remove_0;
+        mb_replace[1] = mb[1];
+        mb_replace -= remove_1;
+      }
+      mb_replace += 2;
+
       mb += 2;
       n_left -= 2;
     }
@@ -434,6 +763,8 @@ VNET_DEVICE_CLASS_TX_FN (dpdk_device_class) (vlib_main_t * vm,
 
   while (n_left > 0)
     {
+      int remove_0 = 0;
+
       b[0] = vlib_buffer_from_rte_mbuf (mb[0]);
       all_or_flags |= b[0]->flags;
       VLIB_BUFFER_TRACE_TRAJECTORY_INIT (b[0]);
@@ -445,12 +776,37 @@ VNET_DEVICE_CLASS_TX_FN (dpdk_device_class) (vlib_main_t * vm,
 	if (b[0]->flags & VLIB_BUFFER_IS_TRACED)
 	  dpdk_tx_trace_buffer (dm, node, xd, queue_id, b[0]);
 
+      /* Terragraph: Handle jumbo frames by segmenting and transmitting mbufs
+       * individually. Remove jumbo frames from the mbuf array after they have
+       * already been enqueued for transmission.
+       */
+      if (rte_pktmbuf_pkt_len (mb[0]) > TG_WIL6210_NO_JUMBO_SEG_MTU &&
+          xd->pmd == VNET_DPDK_PMD_WIL6210)
+        {
+          tg_jumbo_frame_segmentation_tx (xd, mb[0]);
+          remove_0 = 1;
+          n_removed++;
+        }
+
+      if (n_removed > 0) {
+        mb_replace[0] = mb[0];
+        mb_replace -= remove_0;
+      }
+      mb_replace++;
+
       mb++;
       n_left--;
     }
 
+  /* Clean up array after shifting mbuf elements to remove jumbo frames. */
+  while (mb_replace != mb)
+    {
+      mb_replace[0] = NULL;
+      mb_replace++;
+    }
+
   /* transmit as many packets as possible */
-  tx_pkts = n_packets = mb - ptd->mbufs;
+  tx_pkts = n_packets = mb - n_removed - ptd->mbufs;
   n_left = tx_burst_vector_internal (vm, xd, ptd->mbufs, n_packets, &do_free);
 
   {
diff --git a/src/plugins/dpdk/device/dpdk.h b/src/plugins/dpdk/device/dpdk.h
index b30f1dc13..14a8c5564 100644
--- a/src/plugins/dpdk/device/dpdk.h
+++ b/src/plugins/dpdk/device/dpdk.h
@@ -55,6 +55,7 @@
 
 #include <vlib/pci/pci.h>
 #include <vnet/flow/flow.h>
+#include <vnet/ethernet/ethernet.h>
 
 extern vnet_device_class_t dpdk_device_class;
 extern vlib_node_registration_t dpdk_input_node;
@@ -165,6 +166,22 @@ typedef struct
   i16 buffer_advance;
 } dpdk_flow_lookup_entry_t;
 
+/*
+ * Terragraph: Jumbo frame support via segmentation and custom header with
+ *   ethernet type 0xFF71.
+ */
+#define TG_JUMBO_FRAME_PROTOCOL_VERSION 1
+#define TG_WIL6210_NO_JUMBO_SEG_MTU 4000
+#define TG_JUMBO_FRAME_SEG_ARRAY_LEN 16
+
+typedef CLIB_PACKED (struct {
+  ethernet_header_t e;
+  u8 protocol_version;
+  u8 packet_id;
+  u8 seg_index;
+  u8 last_seg;
+}) tg_seg_header_t;
+
 typedef struct
 {
   CLIB_CACHE_LINE_ALIGN_MARK (cacheline0);
@@ -244,6 +261,10 @@ typedef struct
   u32 queue_stats_tot_arrived_bytes[TGHQOS_SCHED_PIPES_PER_PORT];
   u32 queue_stats_avg_arrived_bytes_per_ms[TGHQOS_SCHED_PIPES_PER_PORT];
 
+  u8 tg_jumbo_frame_tx_id;
+  struct rte_mbuf *tg_jumbo_frame_segs[TGHQOS_SCHED_PIPES_PER_PORT]
+                                      [TG_JUMBO_FRAME_SEG_ARRAY_LEN];
+
   /* mac address */
   u8 *default_mac_address;
 
diff --git a/src/plugins/dpdk/device/node.c b/src/plugins/dpdk/device/node.c
index 3c6242d08..255aca41e 100644
--- a/src/plugins/dpdk/device/node.c
+++ b/src/plugins/dpdk/device/node.c
@@ -21,6 +21,7 @@
 #include <vnet/ethernet/ethernet.h>
 #include <dpdk/buffer.h>
 #include <dpdk/device/dpdk.h>
+#include <dpdk/dynfield/dynfield.h>
 #include <vnet/classify/vnet_classify.h>
 #include <vnet/mpls/packet.h>
 #include <vnet/handoff.h>
@@ -282,6 +283,70 @@ dpdk_process_flow_offload (dpdk_device_t * xd, dpdk_per_thread_data_t * ptd,
     }
 }
 
+/**
+ * Terragraph: Reassemble a jumbo frame by creating mbuf linkage.
+ *
+ * @return pointer to first mbuf segment in reassembled packet
+ */
+static_always_inline struct rte_mbuf *
+tg_jumbo_frame_reassemble (dpdk_device_t *xd, int link_id, u8 packet_id,
+                           int segs)
+{
+  tg_seg_header_t *tg_hdr;
+  struct rte_mbuf *mb, *ret_mb;
+  int i;
+
+  u32 tot_pkt_len = 0;
+  u16 tot_segs = 0;
+
+  /* Verify each segment has the same packet id, and sum total packet length,
+   * not including the jumbo frame segmentation header. */
+  for (i = 0; i < segs; i++)
+  {
+    mb = xd->tg_jumbo_frame_segs[link_id][i];
+    if (mb == NULL)
+      return NULL;
+
+    tg_hdr = (void *)(mb->buf_addr + mb->data_off);
+    if (tg_hdr->packet_id != packet_id)
+      return NULL;
+
+    tot_pkt_len += mb->pkt_len - sizeof (tg_seg_header_t);
+    /* Depending on buffer space, a packet that was originally one segment when
+     * separated out of the jumbo frame may be received as a packet containing
+     * two segments. */
+    tot_segs += mb->nb_segs;
+  }
+
+  ret_mb = xd->tg_jumbo_frame_segs[link_id][0];
+  /* Only the first mbuf in the chain has the total number of segments and
+   * actual packet length. */
+  ret_mb->nb_segs = tot_segs;
+  ret_mb->pkt_len = tot_pkt_len;
+
+  /* Adjust data_off and data_len to skip the jumbo frame segmentation header,
+   * and clear segment array. */
+  for (i = 0; i < segs; i++)
+    {
+      mb = xd->tg_jumbo_frame_segs[link_id][i];
+
+      mb->data_off += sizeof (tg_seg_header_t);
+      mb->data_len -= sizeof (tg_seg_header_t);
+
+      if (mb->next != NULL)
+        {
+          mb = mb->next;
+        }
+
+      mb->next =
+          (i == segs - 1) ? NULL : xd->tg_jumbo_frame_segs[link_id][i + 1];
+
+      xd->tg_jumbo_frame_segs[link_id][i] = NULL;
+    }
+
+  return ret_mb;
+}
+
 static_always_inline u32
 dpdk_device_input (vlib_main_t * vm, dpdk_main_t * dm, dpdk_device_t * xd,
 		   vlib_node_runtime_t * node, u32 thread_index, u16 queue_id)
@@ -320,6 +385,80 @@ dpdk_device_input (vlib_main_t * vm, dpdk_main_t * dm, dpdk_device_t * xd,
   if (n_rx_packets == 0)
     return 0;
 
+  /* Terragraph: Check if each received packet is a segment of a jumbo frame.
+   * Remove and store any segments. Try reassembly when last segment arrives,
+   * assuming in-order arrival of segments.
+   */
+  if (xd->pmd == VNET_DPDK_PMD_WIL6210)
+    {
+      struct rte_mbuf **mb_replace = mb = ptd->mbufs;
+      struct rte_mbuf *reassembled;
+      int n_removed = 0, link_id;
+      ethernet_header_t *e;
+      tg_seg_header_t *tg_hdr;
+
+      n_left = n_rx_packets;
+      while (n_left > 0)
+        {
+          int remove_0 = 0;
+
+          e = (void *)(mb[0]->buf_addr + mb[0]->data_off);
+          if (clib_net_to_host_u16 (e->type) == ETHERNET_TYPE_TG_JUMBO)
+            {
+              tg_hdr = (void *)e;
+
+              link_id = wigig_mbuf_link_id_get (mb[0]);
+              if (xd->tg_jumbo_frame_segs[link_id][tg_hdr->seg_index] !=
+                  NULL)
+                {
+                  /* Only one segmented jumbo frame can be in flight at a time
+                   * per peer per sector. If an existing segment has not been
+                   * reassembled when a new one with the same index arrives,
+                   * drop it.
+                   */
+                  rte_pktmbuf_free (
+                      xd->tg_jumbo_frame_segs[link_id][tg_hdr->seg_index]);
+                }
+              /* Save this mbuf in segment array for reassembly, and remove it
+               * from the mbuf array that is being processed. */
+              xd->tg_jumbo_frame_segs[link_id][tg_hdr->seg_index] = mb[0];
+              n_removed++;
+              remove_0 = 1;
+              if (tg_hdr->last_seg)
+                {
+                  reassembled = tg_jumbo_frame_reassemble (
+                      xd, link_id, tg_hdr->packet_id, tg_hdr->seg_index + 1);
+                  if (reassembled != NULL)
+                    {
+                      /* Place the reassembled jumbo frame back into the array
+                       * for processing. */
+                      mb[0] = reassembled;
+                      n_removed--;
+                      remove_0 = 0;
+                    }
+                }
+            }
+
+          if (n_removed > 0)
+            {
+              mb_replace[0] = mb[0];
+              mb_replace -= remove_0;
+            }
+          mb_replace++;
+
+          mb++;
+          n_left--;
+        }
+      /* Clean up array after shifting mbuf elements to remove segments. */
+      while (mb_replace != mb)
+        {
+          mb_replace[0] = NULL;
+          mb_replace++;
+        }
+
+      n_rx_packets -= n_removed;
+    }
+
   /* Update buffer template */
   vnet_buffer (bt)->sw_if_index[VLIB_RX] = xd->sw_if_index;
   bt->error = node->errors[DPDK_ERROR_NONE];
diff --git a/src/vnet/ethernet/ethernet.h b/src/vnet/ethernet/ethernet.h
index 3da989dcd..46ef7f09d 100644
--- a/src/vnet/ethernet/ethernet.h
+++ b/src/vnet/ethernet/ethernet.h
@@ -130,7 +130,7 @@ typedef u32 (ethernet_flag_change_function_t)
   (vnet_main_t * vnm, struct vnet_hw_interface_t * hi, u32 flags);
 
 #define ETHERNET_MIN_PACKET_BYTES  64
-#define ETHERNET_MAX_PACKET_BYTES  9216
+#define ETHERNET_MAX_PACKET_BYTES  10240
 
 /* ethernet dataplane loads mac address as u64 for efficiency */
 typedef union ethernet_interface_address
diff --git a/src/vnet/ethernet/types.def b/src/vnet/ethernet/types.def
index c7a472213..2d21002e1 100644
--- a/src/vnet/ethernet/types.def
+++ b/src/vnet/ethernet/types.def
@@ -111,3 +111,4 @@ ethernet_type (0x9200, VLAN_9200)
 ethernet_type (0x9999, PGLAN)
 ethernet_type (0xFEFE, SRP_ISIS)
 ethernet_type (0xFFFF, RESERVED)
+ethernet_type (0xFF71, TG_JUMBO)
-- 
2.30.2

